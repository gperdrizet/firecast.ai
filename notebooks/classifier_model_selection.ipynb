{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "As a first pass at developing a machine learning model to predict California wildfires I will evaluate and tune several different gradient boosting algorithms. The procedure will be as follows:\n",
    "\n",
    "1. **Classifier selection:** Find the best classification algorithm for the data based on F1 score compute time and memory requirements\n",
    "2. **Metaparameter optimization:** Optimize data metaparameters such as rolling window width\n",
    "3. **Class imbalance:** Generate a strategy to deal with the unbalanced nature of the classes\n",
    "4. **Hyperparameter optimization:** Tune model hyperparameters\n",
    "5. **Feature importance:** Investigate feature importance and possibly trim/apply dimensionality reduction techniques to the data\n",
    "6. **Model robustness:** How does the model perform after repeated sampling? Are scores stable?\n",
    "\n",
    "There are two anticipated issues which will need to be dealt with first:\n",
    "\n",
    "1. Large dataset size - current working dataset has 7.3 million observations of 25 variables and this is likely to grow as the project progresses\n",
    "2. Highly imbalanced data (~20 times more observations without fire than with)\n",
    "\n",
    "Future goals are to add several more factors from various data sources including: elevation, population density, time since last fire and total fires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and notebook setup\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from statistics import mean\n",
    "from memory_profiler import memory_usage\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "raw_data_file = '../data/stratified_training_data/1992-2015_training_data_raw_n100000_ks_pval0.3.1.csv'\n",
    "\n",
    "rand_seed = 42\n",
    "classifier_jobs = 4\n",
    "optimization_jobs = 2\n",
    "max_jobs = classifier_jobs * optimization_jobs\n",
    "\n",
    "sample_size = 10000\n",
    "repetitions = 5\n",
    "train_test_split_ratio = 0.3\n",
    "cv_folds = 5\n",
    "n_doublings = 8\n",
    "scoring_func = make_scorer(average_precision_score)\n",
    "scoring_func_name = \"Average precision\"\n",
    "grid_search_iterations = 500\n",
    "\n",
    "plot_grid_resolution = 500\n",
    "contourf_levels = 500\n",
    "\n",
    "weather_variables = [\n",
    "    'weather_bin_month',\n",
    "    'weather_bin_year',\n",
    "    'air.sfc',\n",
    "    'rhum.2m',\n",
    "    'dpt.2m',\n",
    "    'pres.sfc',\n",
    "    'uwnd.10m', \n",
    "    'vwnd.10m',\n",
    "    'veg',\n",
    "    'lat',\n",
    "    'lon',\n",
    "    'ignition'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def k_random_sample(data, k):\n",
    "    # Takes a data frame and an number of observations\n",
    "    # returns dataframe containing k from n pseudorandom\n",
    "    # observations with out replacement\n",
    "    \n",
    "    n = len(data)\n",
    "    indices = random.sample(range(0, n), k)\n",
    "    return data.iloc[indices]\n",
    "\n",
    "def stratified_sample(data, n):\n",
    "    # takes a datafram and a sample size n, returns\n",
    "    # n observations with positive and negative class\n",
    "    # frequency matched to orignal data\n",
    "    \n",
    "    # split positive and negative datsets up\n",
    "    ignitions = data[data['ignition'] == 1]\n",
    "    no_ignitions = data[data['ignition'] == 0]\n",
    "    \n",
    "    # Calculate ignition & no ignition sample sizes\n",
    "    ignition_fraction = len(ignitions) / len(data)\n",
    "    ignition_sample_size = int((n * ignition_fraction))\n",
    "    no_ignition_sample_size = int((n * (1 - ignition_fraction)))\n",
    "    \n",
    "    # sample data\n",
    "    no_ignitions_sample = k_random_sample(no_ignitions, no_ignition_sample_size)\n",
    "    ignitions_sample = k_random_sample(ignitions, ignition_sample_size)\n",
    "\n",
    "    # combine\n",
    "    sampled_data = no_ignitions_sample.append(ignitions_sample)\n",
    "    \n",
    "    return sampled_data\n",
    "\n",
    "def cross_validate_classifier(classifier, X_train, y_train, folds, scoring_func):\n",
    "    # Takes a classifier, x and y training data, a number of folds for\n",
    "    # cross validation and a scoring function. Runs cross validation and returns\n",
    "    # array of scores from each fold\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=folds)\n",
    "    cross_val_scores = cross_val_score(classifier, X_train, y_train, scoring=scoring_func, cv=cv)\n",
    "    \n",
    "    return cross_val_scores\n",
    "\n",
    "def fit_model(classifier, X, y):\n",
    "    # Takes classifier, data and labels, returns\n",
    "    # fit model\n",
    "    classifier.fit(X, y)\n",
    "    return classifier\n",
    "\n",
    "def display_confusion_matrix(classifier, class_names, x_test, y_test):\n",
    "    # Takes a fit classifier, the class names as a list and\n",
    "    # test data. Prints raw confusion matrix and plots\n",
    "    # normalized confusion matrix\n",
    "\n",
    "    raw_cm = confusion_matrix(y_test, classifier.predict(x_test))\n",
    "    print(\"Raw count confusion matrix\")\n",
    "    print(raw_cm)\n",
    "    \n",
    "    normalized_cm = plot_confusion_matrix(\n",
    "        classifier,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize='true'\n",
    "    )\n",
    "\n",
    "    normalized_cm.ax_.set_title(\"Normalized confusion matrix\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def calc_false_neg_pos_rate(model, x_test, y_test):\n",
    "    # Takes a fit model and test data, returns \n",
    "    # false positive and negative rates\n",
    "    \n",
    "    cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    FP = cm[0][1]\n",
    "\n",
    "    false_neg_rate = FN / (FN + TN)\n",
    "    false_pos_rate = FP / (FP + TN)\n",
    "    \n",
    "    return false_neg_rate, false_pos_rate\n",
    "\n",
    "def scale_weather_variables(weather_variables, X_train, X_test):\n",
    "    # Uses StandardScaler to convert data to Z-score. Takes list of\n",
    "    # weather variable names to scale and train/test data. Calculates\n",
    "    # transformation from test data, applies same transform to\n",
    "    # train and test data, returns scaled data.\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[weather_variables])\n",
    "\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    \n",
    "    X_train[weather_variables] = scaler.transform(X_train[weather_variables])\n",
    "    X_test[weather_variables] = scaler.transform(X_test[weather_variables])\n",
    "    \n",
    "    pd.options.mode.chained_assignment = 'warn'  # default='warn'\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def make_train_test_sample(dataset, sample_size, train_test_split_ratio, rand_seed):\n",
    "    # Takes data in dataframe, sample size, train test split\n",
    "    # ratio and random seed. Samples n datapoints from dataset and then\n",
    "    # runs stratified train test split on sample.\n",
    "    # return stratified train test split data\n",
    "    \n",
    "    column_names = dataset.columns\n",
    "    \n",
    "    sampled_data = stratified_sample(dataset, sample_size)\n",
    "\n",
    "    y = sampled_data['ignition']\n",
    "    X = sampled_data.drop('ignition', axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y, \n",
    "        test_size=train_test_split_ratio, \n",
    "        random_state=rand_seed, \n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def FP_rate_scorer(y_test, y_pred):\n",
    "    # Calulates false positive rate from test data and\n",
    "    # predictions. For use with make_scorer\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    false_pos_rate = FP / (FP + TN)\n",
    "    \n",
    "    return false_pos_rate\n",
    "\n",
    "def FN_rate_scorer(y_test, y_pred):\n",
    "    # Calulates false positive rate from test data and\n",
    "    # predictions. For use with make_scorer\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    false_neg_rate = FN / (FN + TN)\n",
    "    \n",
    "    return false_neg_rate\n",
    "\n",
    "def tune_class_weight(\n",
    "    class_weights,\n",
    "    max_jobs,\n",
    "    rand_seed,\n",
    "    data,\n",
    "    repitions\n",
    "):\n",
    "    # Takes class weight list, number of parallel jobs\n",
    "    # A random seed and training data. Itterates over\n",
    "    # class weights. Stores and returns F1 score,\n",
    "    # false positive and false negative rates for each\n",
    "    # class weight in a data frame.\n",
    "    \n",
    "    model_scores_columns = [\n",
    "        'Class weight',\n",
    "        'CV {} score'.format(scoring_func_name),\n",
    "        'CV False positive rate',\n",
    "        'CV False negative rate'\n",
    "    ]\n",
    "    \n",
    "    model_scores = pd.DataFrame(columns=model_scores_columns)\n",
    "\n",
    "    for class_weight in class_weights:\n",
    "        \n",
    "        for i in range(repitions):\n",
    "            \n",
    "            # draw new stratifited sample and run train test split\n",
    "            X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "                data_daily_mean, \n",
    "                sample_size, \n",
    "                train_test_split_ratio, \n",
    "                rand_seed\n",
    "            )\n",
    "\n",
    "            # Standardize weather variables\n",
    "            X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "\n",
    "            classifier = XGBClassifier(\n",
    "                n_jobs = max_jobs,\n",
    "                scale_pos_weight = class_weight,\n",
    "                random_state = rand_seed\n",
    "            )\n",
    "\n",
    "            classifier.fit(X_train, y_train)\n",
    "\n",
    "            cross_val_scores = cross_validate_classifier(\n",
    "                classifier, \n",
    "                X_train, \n",
    "                y_train, \n",
    "                cv_folds, \n",
    "                scoring_func\n",
    "            )\n",
    "\n",
    "            score = mean(cross_val_scores)\n",
    "\n",
    "            cross_val_FP_rates = cross_validate_classifier(\n",
    "                classifier, \n",
    "                X_train, \n",
    "                y_train, \n",
    "                cv_folds, \n",
    "                make_scorer(FP_rate_scorer)\n",
    "            ) \n",
    "\n",
    "            cross_val_FP_rate = mean(cross_val_FP_rates)\n",
    "\n",
    "            cross_val_FN_rates = cross_validate_classifier(\n",
    "                classifier, \n",
    "                X_train, \n",
    "                y_train, \n",
    "                cv_folds, \n",
    "                make_scorer(FN_rate_scorer)\n",
    "            ) \n",
    "\n",
    "            cross_val_FN_rate = mean(cross_val_FN_rates)\n",
    "\n",
    "            model_scores = model_scores.append(pd.Series([\n",
    "                class_weight,\n",
    "                np.round(score,3), \n",
    "                np.round(cross_val_FP_rate,3), \n",
    "                np.round(cross_val_FN_rate,3)\n",
    "            ], index=model_scores.columns), ignore_index=True)\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def tune_hyperparameters(\n",
    "    classifier,\n",
    "    param_dist, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    num_jobs, \n",
    "    search_iterations, \n",
    "    scoring_func\n",
    "):\n",
    "    # Tunes arbitraty hyperparamter(s) takes a classifier\n",
    "    # a parameter distribution as a dictionary, training data\n",
    "    # a number of parallel jobs, a number of search iterations\n",
    "    # and a scoring function to use for cross validation\n",
    "    # returns winning model and cross validation results as\n",
    "    # data frame\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        classifier, \n",
    "        param_distributions=param_dist,\n",
    "        scoring=scoring_func,\n",
    "        n_iter=search_iterations,\n",
    "        n_jobs=num_jobs\n",
    "    )\n",
    "\n",
    "    best_model = random_search.fit(X_train, y_train)\n",
    "    \n",
    "    return best_model, random_search\n",
    "\n",
    "def regularize_grid(x, y, z, resolution):\n",
    "    # Takes three coordinate grids and a resolution\n",
    "    # interpolates and resamples so frequencys match\n",
    "    # returns regularized data. For use in\n",
    "    # constructing heatmaps\n",
    "\n",
    "    # target grid to interpolate to\n",
    "    xi = np.arange(min(x), max(x), ((max(x) - min(x)) / resolution))\n",
    "    yi = np.arange(min(y), max(y), ((max(y) - min(y)) / resolution))\n",
    "    xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "    # interpolate\n",
    "    zi = griddata((x, y), z, (xi, yi), method='linear')\n",
    "    \n",
    "    return xi, yi, zi\n",
    "    \n",
    "def plot_relative_feature_importance(model, data, x_test, x_tick_size):\n",
    "    # Takes a fit model, orignal data and test data, plots relative feature\n",
    "    # importance\n",
    "    \n",
    "    column_names = x_test.columns\n",
    "    \n",
    "    if 'weather_bin_time' in column_names:\n",
    "        x_test = x_test.drop('weather_bin_time', axis=1)\n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_names = np.array(list(x_test))\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.rc('axes', titlesize=30)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=30)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=x_tick_size)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=25)    # fontsize of the tick labels\n",
    "    plt.title(\"Feature importance\")\n",
    "    plt.bar(range(x_test.shape[1]), importances[indices],\n",
    "           color=\"darkblue\", align=\"center\")\n",
    "    plt.xticks(np.arange(len(indices)), feature_names[indices], rotation='vertical')\n",
    "    plt.xlim([-1, x_test.shape[1]])\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Relative importance\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_bin_month</th>\n",
       "      <th>weather_bin_year</th>\n",
       "      <th>air.sfc</th>\n",
       "      <th>rhum.2m</th>\n",
       "      <th>dpt.2m</th>\n",
       "      <th>pres.sfc</th>\n",
       "      <th>uwnd.10m</th>\n",
       "      <th>vwnd.10m</th>\n",
       "      <th>veg</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>ignition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "      <td>56718.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>6.522004</td>\n",
       "      <td>2003.488857</td>\n",
       "      <td>289.088516</td>\n",
       "      <td>49.092721</td>\n",
       "      <td>274.747569</td>\n",
       "      <td>91521.722452</td>\n",
       "      <td>1.056332</td>\n",
       "      <td>0.149949</td>\n",
       "      <td>30.654752</td>\n",
       "      <td>37.131682</td>\n",
       "      <td>-119.522121</td>\n",
       "      <td>0.045964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.429307</td>\n",
       "      <td>6.931885</td>\n",
       "      <td>13.754099</td>\n",
       "      <td>26.129440</td>\n",
       "      <td>7.382174</td>\n",
       "      <td>6937.239898</td>\n",
       "      <td>2.699176</td>\n",
       "      <td>3.278275</td>\n",
       "      <td>22.749310</td>\n",
       "      <td>2.564622</td>\n",
       "      <td>2.503922</td>\n",
       "      <td>0.209409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>245.539960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>198.476650</td>\n",
       "      <td>67680.950000</td>\n",
       "      <td>-12.885849</td>\n",
       "      <td>-15.892535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.683890</td>\n",
       "      <td>-124.340800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>279.103145</td>\n",
       "      <td>26.682617</td>\n",
       "      <td>269.964270</td>\n",
       "      <td>87154.098750</td>\n",
       "      <td>-0.729976</td>\n",
       "      <td>-2.051666</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>34.990290</td>\n",
       "      <td>-121.470900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>286.778900</td>\n",
       "      <td>45.410180</td>\n",
       "      <td>275.309430</td>\n",
       "      <td>92312.085000</td>\n",
       "      <td>1.047374</td>\n",
       "      <td>0.112423</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>36.837940</td>\n",
       "      <td>-119.905100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>297.377017</td>\n",
       "      <td>71.062552</td>\n",
       "      <td>280.183288</td>\n",
       "      <td>97031.256250</td>\n",
       "      <td>2.739596</td>\n",
       "      <td>2.255397</td>\n",
       "      <td>43.600000</td>\n",
       "      <td>39.304180</td>\n",
       "      <td>-117.411700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>334.044430</td>\n",
       "      <td>100.030075</td>\n",
       "      <td>296.415040</td>\n",
       "      <td>102960.590000</td>\n",
       "      <td>15.625641</td>\n",
       "      <td>22.613800</td>\n",
       "      <td>83.700000</td>\n",
       "      <td>41.971820</td>\n",
       "      <td>-114.364500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weather_bin_month  weather_bin_year       air.sfc       rhum.2m  \\\n",
       "count       56718.000000      56718.000000  56718.000000  56718.000000   \n",
       "mean            6.522004       2003.488857    289.088516     49.092721   \n",
       "std             3.429307          6.931885     13.754099     26.129440   \n",
       "min             1.000000       1992.000000    245.539960      1.000000   \n",
       "25%             4.000000       1997.000000    279.103145     26.682617   \n",
       "50%             7.000000       2003.000000    286.778900     45.410180   \n",
       "75%             9.000000       2010.000000    297.377017     71.062552   \n",
       "max            12.000000       2015.000000    334.044430    100.030075   \n",
       "\n",
       "             dpt.2m       pres.sfc      uwnd.10m      vwnd.10m           veg  \\\n",
       "count  56718.000000   56718.000000  56718.000000  56718.000000  56718.000000   \n",
       "mean     274.747569   91521.722452      1.056332      0.149949     30.654752   \n",
       "std        7.382174    6937.239898      2.699176      3.278275     22.749310   \n",
       "min      198.476650   67680.950000    -12.885849    -15.892535      0.000000   \n",
       "25%      269.964270   87154.098750     -0.729976     -2.051666      8.200000   \n",
       "50%      275.309430   92312.085000      1.047374      0.112423     30.600000   \n",
       "75%      280.183288   97031.256250      2.739596      2.255397     43.600000   \n",
       "max      296.415040  102960.590000     15.625641     22.613800     83.700000   \n",
       "\n",
       "                lat           lon      ignition  \n",
       "count  56718.000000  56718.000000  56718.000000  \n",
       "mean      37.131682   -119.522121      0.045964  \n",
       "std        2.564622      2.503922      0.209409  \n",
       "min       32.683890   -124.340800      0.000000  \n",
       "25%       34.990290   -121.470900      0.000000  \n",
       "50%       36.837940   -119.905100      0.000000  \n",
       "75%       39.304180   -117.411700      0.000000  \n",
       "max       41.971820   -114.364500      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv(raw_data_file, low_memory=False)\n",
    "raw_data = raw_data[weather_variables]\n",
    "\n",
    "# Shuffel row order\n",
    "raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier selection: kitchen sink approach\n",
    "\n",
    "First step is to throw a bunch of different classifiers with default settings at the problem and see how they do. See list below for contenders.\n",
    "\n",
    "We will start with a small sample of data to quickly get a sense of how well each classifier works. Hopefully we can discard some to make test run times shorter in the next round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLearn classifiers\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# List of classifier descriptions for plotting / dataframes\n",
    "classifier_descriptions = [\n",
    "    'Logit. regres.',\n",
    "    'Decision tree',\n",
    "    'K neighbors',\n",
    "    'Rand. forest',\n",
    "    'QDA',\n",
    "    'XGBoost',\n",
    "    'CatBoost',\n",
    "    'LightGBM',\n",
    "    'AdaBoost',\n",
    "    'Linear SVM',\n",
    "    'RBF SVM',\n",
    "    'Naive Bayes'\n",
    "]\n",
    "\n",
    "# Classifiers with parameters. Set parallism and rand_seed if avalible.\n",
    "# Also set 'rule of thumb' class weight if avalible for that classifier.\n",
    "\n",
    "num_negative_observations = len(raw_data[raw_data['ignition'] == 0])\n",
    "num_positive_observations = len(raw_data[raw_data['ignition'] == 1])\n",
    "class_ratio = num_negative_observations / num_positive_observations\n",
    "\n",
    "class_weight_dict = {\n",
    "    0: (1 / class_ratio),\n",
    "    1: 1 - (1 / class_ratio)\n",
    "}\n",
    "\n",
    "classifiers = (\n",
    "    \n",
    "    LogisticRegression(\n",
    "        n_jobs = max_jobs, \n",
    "        random_state = rand_seed,\n",
    "        class_weight = class_weight_dict\n",
    "    ),\n",
    "    \n",
    "    DecisionTreeClassifier( \n",
    "        random_state = rand_seed,\n",
    "        class_weight = class_weight_dict\n",
    "    ),\n",
    "    \n",
    "    KNeighborsClassifier(\n",
    "        n_jobs = max_jobs        \n",
    "    ),\n",
    "    \n",
    "    RandomForestClassifier(\n",
    "        n_jobs = max_jobs,\n",
    "        class_weight = class_weight_dict,\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    \n",
    "    XGBClassifier(\n",
    "        n_jobs = max_jobs,\n",
    "        scale_pos_weight = class_ratio,\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    CatBoostClassifier(\n",
    "        thread_count = max_jobs, \n",
    "        silent = True,\n",
    "        scale_pos_weight = class_ratio,\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    LGBMClassifier(\n",
    "        n_jobs = max_jobs,\n",
    "        scale_pos_weight = class_ratio,\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    AdaBoostClassifier(random_state = rand_seed),\n",
    "    \n",
    "    SVC(kernel = \"linear\",\n",
    "        class_weight = 'balanced',\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    SVC(\n",
    "        class_weight = 'balanced',\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    GaussianNB(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over classifier list, run k-fold cross validation on stratified \n",
    "# training sample for each. Report mean and SD of score, run time and peak memory use\n",
    "\n",
    "# Start empty dataframe to hold results\n",
    "classifier_data = pd.DataFrame(columns=[\n",
    "    'Classifier',\n",
    "    'Sample size',\n",
    "    'CV folds',\n",
    "    'Raw scores',\n",
    "    'Mean {} score'.format(scoring_func_name),\n",
    "    '{} score SD'.format(scoring_func_name),\n",
    "    'Peak memory (GB)',\n",
    "    'Run time (min.)'\n",
    "])\n",
    "\n",
    "# Loop over classifiers\n",
    "for classifier, description in zip(classifiers, classifier_descriptions):\n",
    "    \n",
    "    dTs = []\n",
    "    max_mems = []\n",
    "    raw_scores = []\n",
    "    \n",
    "    for i in range(repetitions):\n",
    "        \n",
    "        # Take stratified sample data of data and do stratified train_test split    \n",
    "        X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "            raw_data, \n",
    "            sample_size, \n",
    "            train_test_split_ratio, \n",
    "            rand_seed\n",
    "        )\n",
    "        \n",
    "        start = time()\n",
    "\n",
    "        # Cross validate classifier, tracking memory usage\n",
    "        mem_usage, cross_val_scores = memory_usage((cross_validate_classifier, (\n",
    "            classifier, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            cv_folds, \n",
    "            scoring_func)\n",
    "        ), retval=True)\n",
    "\n",
    "        dT = np.round(((time() - start)/60),2)\n",
    "        dTs.append(dT)\n",
    "        raw_scores = np.concatenate((raw_scores, cross_val_scores))\n",
    "        max_mems = np.concatenate((max_mems, mem_usage))\n",
    "\n",
    "    mean_score = np.round(mean(raw_scores),3)\n",
    "    sd_score = np.round(np.std(raw_scores),4)\n",
    "    max_mem = np.round((max(max_mems) / 1000),3)\n",
    "    \n",
    "    # Store run results in dataframe\n",
    "    classifier_data = classifier_data.append(pd.Series([\n",
    "        description,\n",
    "        sample_size,\n",
    "        cv_folds,\n",
    "        cross_val_scores,\n",
    "        mean_score,\n",
    "        sd_score,\n",
    "        max_mem,\n",
    "        dT\n",
    "    ], index=classifier_data.columns), ignore_index=True)\n",
    "    \n",
    "#     print(\"Finished: {}\".format(description))\n",
    "#     print(raw_scores, mean_score)\n",
    "\n",
    "# Sort results by score\n",
    "classifier_data = classifier_data.sort_values(['Mean {} score'.format(scoring_func_name)], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of classifiers using mean score\n",
    "fig = plt.figure(1, figsize=(12, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "bp = ax.boxplot(classifier_data['Raw scores'])\n",
    "ax.set_xticklabels(classifier_data['Classifier'])\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('{} score'.format(scoring_func_name))\n",
    "plt.title('Classifier comparision, 5-fold cross validation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_data.drop('Raw scores', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, our top three winners are gradient boosting algorithms. All three are within a standard deviation of each other, but CatBoost takes ~15 times longer than the other two. Let's focus on the top three and quickly check how well they will scale as the dataset grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier selection: resource requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced classifier set\n",
    "\n",
    "classifier_descriptions = [\n",
    "    'LightGBM',\n",
    "    'CatBoost',\n",
    "    'XGBoost'\n",
    "]\n",
    "\n",
    "classifiers = (\n",
    "    \n",
    "    LGBMClassifier(\n",
    "        n_jobs = max_jobs,\n",
    "        scale_pos_weight = class_ratio,\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    CatBoostClassifier(\n",
    "        thread_count = max_jobs, \n",
    "        silent = True,\n",
    "        scale_pos_weight = class_ratio,\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    "    \n",
    "    XGBClassifier(\n",
    "        n_jobs = max_jobs,\n",
    "        scale_pos_weight = class_ratio,\n",
    "        random_state = rand_seed\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_data = pd.DataFrame(columns=[\n",
    "    'Classifier',\n",
    "    'Sample size',\n",
    "    'Peak memory (GB)',\n",
    "    'Run time (min.)'\n",
    "])\n",
    "\n",
    "size_of_sample = 5000\n",
    "\n",
    "# Loop over range n, doubling the size of the dataset sample each time\n",
    "for i in range(0,(n_doublings+1)):\n",
    "    \n",
    "    # Loop over each classifier, store max memory and run time\n",
    "    for classifier, description in zip(classifiers, classifier_descriptions):\n",
    "    \n",
    "        for i in range(repetitions):\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "                raw_data, \n",
    "                size_of_sample, \n",
    "                train_test_split_ratio, \n",
    "                rand_seed\n",
    "            )\n",
    "        \n",
    "            X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "            \n",
    "            start = time()\n",
    "            mem_usage, model = memory_usage((fit_model, (classifier, X_train, y_train)), retval=True)\n",
    "            dT = np.round(((time() - start)/60),2)\n",
    "\n",
    "            max_mem = np.round((max(mem_usage) / 1000),3)\n",
    "\n",
    "            sample_size_data = sample_size_data.append(pd.Series([\n",
    "                description,\n",
    "                size_of_sample,\n",
    "                max_mem,\n",
    "                dT\n",
    "            ], index=sample_size_data.columns), ignore_index=True)\n",
    "    \n",
    "    size_of_sample = size_of_sample * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x='Sample size', y='Run time (min.)', hue='Classifier', data=sample_size_data)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Run time vs. data sample size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x='Sample size', y='Peak memory (GB)', hue='Classifier', data=sample_size_data)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Peak memory vs. data sample size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like XGBoost is the holistic winner. XGBoost's cross validation scores are close to those of CatBoost and it seems to be significantly faster. It does appear to use slightly more memory, hopefully that won't be a problem. Let's look at it in a bit more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain default model with standard data sample size\n",
    "model = XGBClassifier(\n",
    "    n_jobs = max_jobs,\n",
    "    scale_pos_weight = class_ratio,\n",
    "    random_state = rand_seed\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "    raw_data, \n",
    "    sample_size, \n",
    "    train_test_split_ratio, \n",
    "    rand_seed\n",
    ")\n",
    "\n",
    "X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = np.array(['No ignition', 'Ignition'])\n",
    "display_confusion_matrix(model, class_names, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false positive and negative rates\n",
    "false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(model, X_test, y_test)\n",
    "print(\"False negative rate: {}\".format(np.round(false_neg_rate, 2)))\n",
    "print(\"False positive rate: {}\".format(np.round(false_pos_rate, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the nature of the problem, false negative are more dangerous than false positives. Although our false negative rate is under 10%, even with this small sample, we missed a significant number of fires. Needless to say, there is room for improvement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaparameter optimization: to smooth or not to smooth\n",
    "\n",
    "You may have notices that I loaded three different datasets at the start of this notebook:\n",
    "\n",
    "1. **raw_data:** No significant manipulations beyond collating the various datasets. Has a time resolution of 3 hr. due to the frequency of the original NOAA weather data set.\n",
    "2. **data_rolling_window:** Data was reversed with regard to time and then averaged with a 6 hr. rolling window. This has the effect of assigning the window mean to the time bin at the left of the window. This was done because logically we should care more about weather conditions before the fire was discovered than after.\n",
    "3. **data_daily_mean:** Rolling window data was averaged by day.\n",
    "\n",
    "**Note:** All averaging includes the boolean ignition value. After averaging is complete any noxel with a non-zero ignition value is reassigned a 1. This tends to make the fires discovery 'spread' to earlier times. Again, this is acceptable and even desirable because logically the fire must have started before it was discovered.\n",
    "\n",
    "For more details about these three datasets take a look at the [data preprocessing notebook](https://github.com/gperdrizet/wildfire/blob/master/notebooks/preprocess_data.ipynb).\n",
    "\n",
    "OK, so, let's compare the three sets with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll data with windowed mean\n",
    "data_rolling_window = raw_data.iloc[::-1]\n",
    "data_rolling_window = data_rolling_window.groupby(['lat', 'lon']).rolling(48, on=\"weather_bin_time\").mean()\n",
    "data_rolling_window.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reassign fractional ignition values a '1'\n",
    "ignitions = data_rolling_window[data_rolling_window['ignition'] > 0].copy()\n",
    "no_ignitions = data_rolling_window[data_rolling_window['ignition'] == 0].copy()\n",
    "ignitions['ignition'] = 1\n",
    "\n",
    "data_rolling_window = ignitions.append(no_ignitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average data by day\n",
    "data_daily_mean = data_rolling_window.groupby([\n",
    "    'lat', \n",
    "    'lon', \n",
    "    'weather_bin_year',\n",
    "    'weather_bin_month',\n",
    "    'weather_bin_day'\n",
    "]).mean().reset_index()\n",
    "\n",
    "data_daily_mean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reassign fractional ignition values a '1'\n",
    "ignitions = data_daily_mean[data_daily_mean['ignition'] > 0].copy()\n",
    "no_ignitions = data_daily_mean[data_daily_mean['ignition'] == 0].copy()\n",
    "ignitions['ignition'] = 1\n",
    "\n",
    "data_daily_mean = ignitions.append(no_ignitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over dataset list, run k-fold cross validation on stratified training sample\n",
    "# from each. Report raw scores.\n",
    "\n",
    "dataset_descriptions = [\n",
    "    \"Raw data\",\n",
    "    \"Rolling window\",\n",
    "    \"Daily average\"\n",
    "]\n",
    "\n",
    "datasets = (\n",
    "    raw_data,\n",
    "    data_rolling_window,\n",
    "    data_daily_mean\n",
    ")\n",
    "\n",
    "classifier = XGBClassifier(\n",
    "    n_jobs = max_jobs,\n",
    "    scale_pos_weight = class_ratio,\n",
    "    random_state = rand_seed\n",
    ")\n",
    "\n",
    "# Start empty dataframe to hold results\n",
    "dataset_comparison_results = pd.DataFrame(columns=[\n",
    "    'Data type',\n",
    "    'Raw scores',\n",
    "])\n",
    "\n",
    "# Loop on datasets\n",
    "for dataset, description in zip(datasets, dataset_descriptions):\n",
    "    \n",
    "    cross_val_scores = []\n",
    "    \n",
    "    for i in range(repetitions):\n",
    "  \n",
    "        # Draw train-test sample from dataset\n",
    "        X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "            dataset, \n",
    "            sample_size, \n",
    "            train_test_split_ratio, \n",
    "            rand_seed\n",
    "        )\n",
    "\n",
    "        # Scale weather variables\n",
    "        X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "\n",
    "        # Crossvalidate on training data\n",
    "        scores = cross_validate_classifier(\n",
    "            classifier, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            cv_folds, \n",
    "            scoring_func\n",
    "        )\n",
    "        \n",
    "        cross_val_scores.append(scores)\n",
    "\n",
    "    # Store raw scores\n",
    "    dataset_comparison_results = dataset_comparison_results.append(pd.Series([\n",
    "        description,\n",
    "        cross_val_scores,\n",
    "    ], index=dataset_comparison_results.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparision of datasets by score\n",
    "fig = plt.figure(1, figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "bp = ax.boxplot(dataset_comparison_results['Raw scores'])\n",
    "ax.set_xticklabels(dataset_comparison_results['Data type'])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('CV {} score'.format(scoring_func_name))\n",
    "plt.title('Dataset comparision')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, looks like the daily averages are the winner, though the rolling window is close. Before moving on, let's see what happens if we try to optimize the rolling window width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaparameter optimization: rolling window width\n",
    "\n",
    "The use of a rolling window introduces a possibly extremely important metaparameter: the rolling window width. Let's play with that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over rolling window sizes, run k-fold cross validation on stratified \n",
    "# training sample for each. Report raw scores, false positive and false negative rates.\n",
    "\n",
    "window_widths = range(2,50,2)\n",
    "\n",
    "classifier = XGBClassifier(\n",
    "    n_jobs = max_jobs,\n",
    "    scale_pos_weight = class_ratio,\n",
    "    random_state = rand_seed\n",
    ")\n",
    "\n",
    "# Start empty dataframe to hold results\n",
    "model_scores = pd.DataFrame(columns=[\n",
    "    'Window width',\n",
    "    'CV {} score'.format(scoring_func_name),\n",
    "    'CV False positive rate',\n",
    "    'CV False negative rate'\n",
    "])\n",
    "\n",
    "# Loop over window width\n",
    "for window_width in window_widths:\n",
    "    \n",
    "    # Roll dataset with window \n",
    "    data_rolling_window = raw_data.iloc[::-1]\n",
    "    data_rolling_window = data_rolling_window.groupby(['lat', 'lon']).rolling(window_width, on=\"weather_bin_time\").mean()\n",
    "    data_rolling_window.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    ignitions = data_rolling_window[data_rolling_window['ignition'] > 0].copy()\n",
    "    no_ignitions = data_rolling_window[data_rolling_window['ignition'] == 0].copy()\n",
    "    ignitions['ignition'] = 1\n",
    "\n",
    "    dataset = ignitions.append(no_ignitions)\n",
    "    \n",
    "    # Draw train-test sample from dataset\n",
    "    X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "        dataset, \n",
    "        sample_size, \n",
    "        train_test_split_ratio, \n",
    "        rand_seed\n",
    "    )\n",
    "    \n",
    "    # Scale weather varaibles\n",
    "    X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "    \n",
    "    # Run cross validation on traing data\n",
    "    cross_val_scores = cross_validate_classifier(\n",
    "        classifier, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv_folds, \n",
    "        scoring_func\n",
    "    )\n",
    "\n",
    "    score = mean(cross_val_scores)\n",
    "    \n",
    "    # Run cross validation with false positive rate\n",
    "    cross_val_FP_rates = cross_validate_classifier(\n",
    "        classifier, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv_folds, \n",
    "        make_scorer(FP_rate_scorer)\n",
    "    ) \n",
    "\n",
    "    cross_val_FP_rate = mean(cross_val_FP_rates)\n",
    "\n",
    "    # Run cross validation with false negative rate\n",
    "    cross_val_FN_rates = cross_validate_classifier(\n",
    "        classifier, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv_folds, \n",
    "        make_scorer(FN_rate_scorer)\n",
    "    ) \n",
    "\n",
    "    cross_val_FN_rate = mean(cross_val_FN_rates)\n",
    "\n",
    "    # Store results\n",
    "    model_scores = model_scores.append(pd.Series([\n",
    "        window_width,\n",
    "        np.round(score,3), \n",
    "        np.round(cross_val_FP_rate,3), \n",
    "        np.round(cross_val_FN_rate,3)\n",
    "    ], index=model_scores.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot false positive and negative rates as a function of window size\n",
    "plt.subplots(1,2,figsize=(12,12))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\n",
    "    model_scores['Window width'], \n",
    "    model_scores['CV False negative rate'],\n",
    "    color = \"darkred\",\n",
    "    label = 'False negatives'\n",
    ")\n",
    "plt.xlabel('Window width (hr.)')\n",
    "plt.ylabel('Cross validation rate')\n",
    "plt.title('Window width vs. false negatives')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\n",
    "    model_scores['Window width'], \n",
    "    model_scores['Average CV rate'],\n",
    "    color = \"darkblue\",\n",
    "    label = 'False positives'\n",
    ")\n",
    "plt.xlabel('Window width (hr.)')\n",
    "plt.ylabel('Average CV rate')\n",
    "plt.title('Window width vs. false positives')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score as a function of window size\n",
    "plt.scatter(\n",
    "    model_scores['Window width'], \n",
    "    model_scores['CV {} score'.format(scoring_func_name)],\n",
    "    color = \"darkgreen\",\n",
    "    label ='CV {} score'.format(scoring_func_name),\n",
    ")\n",
    "plt.xlabel('Window width (hr.)')\n",
    "plt.ylabel('CV {} score'.format(scoring_func_name))\n",
    "plt.title('Window width vs. {} score'.format(scoring_func_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization: class weight\n",
    "\n",
    "One of the challenges inherent in this dataset is imbalanced classes. An appripriate class weight can help aleviate this. Also, one of the strange consequences of increasing the window width is an increase in the number of observations labeled fire. Now that we have the window width metaparameter nailed down, let's optimize the class weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class weight search space\n",
    "class_weights = np.logspace(-2, 3, num=25, base=10)\n",
    "\n",
    "# Run cross validation on each class weight, report score\n",
    "# false positive and false negative rates\n",
    "model_scores = tune_class_weight(\n",
    "    class_weights,\n",
    "    max_jobs,\n",
    "    rand_seed,\n",
    "    data_daily_mean,\n",
    "    repitions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot false positive rate, false negative rate and score\n",
    "# as a function of class weight\n",
    "plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\n",
    "    np.log10(model_scores['Class weight']), \n",
    "    model_scores['CV False positive rate'],\n",
    "    color = \"darkblue\",\n",
    "    label = 'False positives'\n",
    ")\n",
    "plt.scatter(\n",
    "    np.log10(model_scores['Class weight']), \n",
    "    model_scores['CV False negative rate'],\n",
    "    color = \"darkred\",\n",
    "    label = 'False negatives'\n",
    ")\n",
    "plt.xlabel('Log10 class weight ratio')\n",
    "plt.ylabel('Cross validation rate')\n",
    "plt.title('Class weight vs. false positives & negatives')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\n",
    "    np.log10(model_scores['Class weight']), \n",
    "    model_scores['CV {} score'.format(scoring_func_name)],\n",
    "    color = \"darkgreen\",\n",
    "    label ='CV {} score'.format(scoring_func_name),\n",
    ")\n",
    "plt.xlabel('Log10 class weight ratio')\n",
    "plt.ylabel('CV {} score'.format(scoring_func_name))\n",
    "plt.title('Class weight vs. {} score'.format(scoring_func_name))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Interesting. We can use larger class weights to drive down the false negative rate at the expense of false positives. Looking at the clearly sigmoidal score curve, the optimum value seems to be between 1 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick and store the class wight which gives the highest score\n",
    "model_scores = model_scores.sort_values(['CV {} score'.format(scoring_func_name)], ascending=[0])\n",
    "model_scores.reset_index(drop=True, inplace=True)\n",
    "class_weight = model_scores.loc[0,'Class weight']\n",
    "print(\"{} optimized class weight: {}\".format(scoring_func_name,np.round(class_weight,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Important to keep in mind here that we can tune our false positive/false negative rates easily with this hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: learning rate and tree count\n",
    "\n",
    "First, let's try taking one sample of the full dataset and then using RandomizedSearchCV to try and find the best values for learning rate and tree count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier whith all the hyperparameters we have determined so far\n",
    "classifier = XGBClassifier(\n",
    "    n_jobs = classifier_jobs,\n",
    "    scale_pos_weight = class_weight,\n",
    "    random_state = rand_seed\n",
    ")\n",
    "\n",
    "# Set search space\n",
    "param_dist = {\n",
    "    'learning_rate': loguniform(0.0001, 1),\n",
    "    'n_estimators': range(1,200),\n",
    "    'max_depth': range(1, 21, 1),\n",
    "    'gamma': np.linspace(0, 10, 101),\n",
    "    'min_child_weight': loguniform(0.0001, 10),\n",
    "    'reg_lambda': loguniform(0.0001, 10)\n",
    "    \n",
    "}\n",
    "\n",
    "# Run randomsearchCV\n",
    "best_model, random_search = tune_hyperparameters(\n",
    "    classifier,\n",
    "    param_dist, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    optimization_jobs, \n",
    "    grid_search_iterations, \n",
    "    scoring_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results to dataframe\n",
    "rand_search_results = pd.DataFrame(random_search.cv_results_).dropna()\n",
    "\n",
    "# Make desnity plot showing the dependenc of score on\n",
    "# learning rate and n_estimators\n",
    "x = rand_search_results['param_n_estimators']\n",
    "y = rand_search_results['param_learning_rate']\n",
    "z = rand_search_results['mean_test_score']\n",
    "xi, yi, zi = regularize_grid(x, y, z, plot_grid_resolution)\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "plt.contourf(xi, yi, zi, contourf_levels, cmap=plt.cm.Blues)\n",
    "plt.xlabel(\"N estimators\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.title(\"Effect of estimator count and \\nlearning rate on score\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprised by how 'rough' hyperparameter space is. Let's keep the winning numbers and save the scores to our log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_learning_rate = rand_search_results.iloc[0]['param_learning_rate']\n",
    "best_n_estimators = rand_search_results.iloc[0]['param_n_estimators']\n",
    "print(\"{} optimized learning rate: {}\".format(scoring_func_name,np.round(best_learning_rate,2)))\n",
    "print(\"{} optimized n estimators: {}\".format(scoring_func_name,np.round(best_n_estimators,2)))\n",
    "\n",
    "best_depth = rand_search_results.iloc[0]['param_max_depth']\n",
    "best_gamma = rand_search_results.iloc[0]['param_gamma']\n",
    "print(\"{} optimized tree depth: {}\".format(scoring_func_name,np.round(best_depth,2)))\n",
    "print(\"{} optimized gamma: {}\".format(scoring_func_name,np.round(best_gamma,2)))\n",
    "\n",
    "best_min_child_weight = rand_search_results.iloc[0]['param_min_child_weight']\n",
    "best_reg_lambda = rand_search_results.iloc[0]['param_reg_lambda']\n",
    "print(\"{} optimized min. child weight: {}\".format(scoring_func_name,np.round(best_min_child_weight,2)))\n",
    "print(\"{} optimized L2 regularization: {}\".format(scoring_func_name,np.round(best_reg_lambda,2)))\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = np.array(['No ignition', 'Ignition'])\n",
    "display_confusion_matrix(best_model, class_names, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: tree depth and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier whith all the hyperparameters we have determined so far\n",
    "classifier = XGBClassifier(\n",
    "    n_jobs = classifier_jobs,\n",
    "    scale_pos_weight = class_weight,\n",
    "    random_state = rand_seed,\n",
    "    learning_rate = best_learning_rate,\n",
    "    n_estimators = best_n_estimators\n",
    ")\n",
    "\n",
    "# Set search space\n",
    "param_dist = {\n",
    "    'max_depth': range(1, 21, 1),\n",
    "    'gamma': np.linspace(0, 10, 101)\n",
    "}\n",
    "\n",
    "# Run randomsearchCV\n",
    "best_model, random_search = tune_hyperparameters(\n",
    "    classifier,\n",
    "    param_dist, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    optimization_jobs, \n",
    "    grid_search_iterations, \n",
    "    scoring_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results to dataframe\n",
    "rand_search_results = pd.DataFrame(random_search.cv_results_).dropna()\n",
    "\n",
    "# Make desnity plot showing the dependenc of score on\n",
    "# learning rate and n_estimators\n",
    "x = rand_search_results['param_max_depth']\n",
    "y = rand_search_results['param_gamma']\n",
    "z = rand_search_results['mean_test_score']\n",
    "xi, yi, zi = regularize_grid(x, y, z, plot_grid_resolution)\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "plt.contourf(xi, yi, zi, contourf_levels, cmap=plt.cm.Blues)\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.ylabel(\"Gamma\")\n",
    "plt.title(\"Effect of tree depth and gamma on score\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again store winning parameter for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_depth = rand_search_results.iloc[0]['param_max_depth']\n",
    "best_gamma = rand_search_results.iloc[0]['param_gamma']\n",
    "print(\"F1 optimized tree depth: {}\".format(np.round(best_depth,2)))\n",
    "print(\"F1 optimized gamma: {}\".format(np.round(best_gamma,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "Now that we have our hyperparameter nailed down, let't take a look at feature importance. First thing to do is train our optimized model on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with tuned hyperparameters\n",
    "classifier = XGBClassifier(\n",
    "    n_jobs = max_jobs,\n",
    "    scale_pos_weight = class_weight,\n",
    "    learning_rate = best_learning_rate,\n",
    "    n_estimators = best_n_estimators,\n",
    "    random_state = rand_seed,\n",
    "    max_depth = best_depth,\n",
    "    gamma = best_gamma\n",
    ")\n",
    "\n",
    "# Stratified test train split the whole dataset\n",
    "X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "    data_daily_mean, \n",
    "    len(data_daily_mean), \n",
    "    train_test_split_ratio, \n",
    "    rand_seed\n",
    ")\n",
    "\n",
    "# Scale weather varibles\n",
    "X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "\n",
    "# Train model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = np.array(['No ignition', 'Ignition'])\n",
    "display_confusion_matrix(classifier, class_names, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(classifier, X_test, y_test)\n",
    "print(\"False negative rate: {}\".format(np.round(false_neg_rate, 2)))\n",
    "print(\"False positive rate: {}\".format(np.round(false_pos_rate, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_relative_feature_importance(classifier, data_daily_mean, X_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like only our top 5 or so features are actually contributing anything. Let's retrain using only those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab top n feature names\n",
    "feature_names = np.array(list(X_train))\n",
    "importances = classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_n_features = feature_names[indices[0:5]]\n",
    "\n",
    "# rebuild training and test sets with feature subset\n",
    "X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "    data_daily_mean, \n",
    "    len(data_daily_mean), \n",
    "    train_test_split_ratio, \n",
    "    rand_seed\n",
    ")\n",
    "\n",
    "X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "\n",
    "X_train_subset = X_train[top_n_features]\n",
    "X_test_subset = X_test[top_n_features]\n",
    "\n",
    "# Train model\n",
    "classifier.fit(X_train_subset, y_train)\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = np.array(['No ignition', 'Ignition'])\n",
    "display_confusion_matrix(classifier, class_names, X_test_subset, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(classifier, X_test_subset, y_test)\n",
    "print(\"False negative rate: {}\".format(np.round(false_neg_rate, 2)))\n",
    "print(\"False positive rate: {}\".format(np.round(false_pos_rate, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model: robustness\n",
    "Let's see how our final model holds up to repeated sampling - are the scores variable? or are the consistent across samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = list()\n",
    "test_scores = list()\n",
    "false_neg_rates = list()\n",
    "false_pos_rates = list()\n",
    "\n",
    "sample_size = 5000\n",
    "\n",
    "for i in range(0, 50):\n",
    "    # rebuild training and test sets with feature subset\n",
    "    X_train, X_test, y_train, y_test = make_train_test_sample(\n",
    "        data_daily_mean, \n",
    "        sample_size, \n",
    "        train_test_split_ratio, \n",
    "        rand_seed\n",
    "    )\n",
    "    \n",
    "    X_train, X_test = scale_weather_variables(weather_variables, X_train, X_test)\n",
    "    \n",
    "    X_train_subset = X_train[top_n_features]\n",
    "    X_test_subset = X_test[top_n_features]\n",
    "\n",
    "    classifier.fit(X_train_subset, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test_subset)\n",
    "    \n",
    "    train_score = f1_score(y_train, classifier.predict(X_train_subset))\n",
    "    test_score = f1_score(y_test, classifier.predict(X_test_subset))\n",
    "        \n",
    "    false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(classifier, X_test_subset, y_test)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    false_neg_rates.append(false_neg_rate)\n",
    "    false_pos_rates.append(false_pos_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "ax = sns.kdeplot(train_scores, label=\"Training data\", shade=True, color=\"darkblue\")\n",
    "ax = sns.kdeplot(test_scores, label=\"Test data\", shade=True, color=\"darkred\")\n",
    "ax.set_title(\"{} score distributions, repeated samples\".format(scoring_func_name))\n",
    "ax.set(xlabel='{} score'.format(scoring_func_name), ylabel='Density')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(false_neg_rates, label=\"False negative\", shade=True, color=\"darkblue\")\n",
    "ax = sns.kdeplot(false_pos_rates, label=\"False positive\", shade=True, color=\"darkred\")\n",
    "ax.set_title(\"False positive and negative rates\\nrepeated samples\")\n",
    "ax.set(xlabel='Rate', ylabel='Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(false_neg_rates, false_pos_rates, s=5)\n",
    "plt.xlabel(\"False negative rate\")\n",
    "plt.ylabel(\"False positive rate\")\n",
    "plt.title(\"False positive vs false negative rate\\nrepeated samples\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Overall, XGBoost was selected as the best classifier for this problem. The initial model performance was improved by optimizing dataset smoothing and hyperparameters. Then feature importance was investigated and lowly important features pruned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work\n",
    "\n",
    "The current model can likely be further improved in four ways:\n",
    "1. Apply neural net based machine learning.\n",
    "2. Add more features to the data such as: elevation, total fires at a location etc.\n",
    "3. Reframe the problem as regression by calculating fire probability, rather than using a binary 'yes'-'no' approach.\n",
    "4. Implement 'fully stratified sampling' i.e. choose samples for training, validation and testing such that the distribution of all factors in the sample match the parent dataset as closely as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
